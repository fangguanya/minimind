"""
æµ‹è¯• UE ä¸“ä¸šåŠ©æ‰‹æ¨¡å‹
"""
import os
import sys
import torch

ROOT_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.append(ROOT_DIR)
os.chdir(ROOT_DIR)

from model.model_minimind import MiniMindConfig, MiniMindForCausalLM
from transformers import AutoTokenizer

def test_model(model_name="ue_sft_pure"):
    device = "cuda:0"
    hidden_size = 512
    num_layers = 8
    
    # åŠ è½½æ¨¡å‹
    print(f"åŠ è½½æ¨¡å‹: {model_name}...")
    lm_config = MiniMindConfig(hidden_size=hidden_size, num_hidden_layers=num_layers)
    tokenizer = AutoTokenizer.from_pretrained(os.path.join(ROOT_DIR, "model"))
    model = MiniMindForCausalLM(lm_config).to(device)
    
    weight_path = os.path.join(ROOT_DIR, f"out/{model_name}_{hidden_size}.pth")
    state_dict = torch.load(weight_path, map_location=device)
    model.load_state_dict(state_dict, strict=False)
    model.eval()
    print(f"Model Params: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M")
    
    # æµ‹è¯•é—®é¢˜
    test_questions = [
        "ä»€ä¹ˆæ˜¯UObjectç±»ï¼Ÿ",
        "UMovieSceneWidgetMaterialTrackå…³è”å“ªäº›ç±»å‹ï¼Ÿ",
        "AActoræœ‰å“ªäº›ä¸»è¦å‡½æ•°ï¼Ÿ",
        "ä»€ä¹ˆæ˜¯UGameplayTaskç±»ï¼Ÿ",
        "FVectoræ˜¯ä»€ä¹ˆï¼Ÿ",
    ]
    
    print("\n" + "="*60)
    print("å¼€å§‹æµ‹è¯•")
    print("="*60)
    
    for question in test_questions:
        # æ„å»ºå¯¹è¯æ ¼å¼
        prompt = f"<|im_start|>user\n{question}<|im_end|>\n<|im_start|>assistant\n"
        
        input_ids = tokenizer.encode(prompt, return_tensors="pt").to(device)
        
        with torch.no_grad():
            output = model.generate(
                input_ids,
                max_new_tokens=256,
                temperature=0.7,
                top_p=0.9,
                do_sample=True,
                pad_token_id=tokenizer.pad_token_id,
                eos_token_id=tokenizer.eos_token_id,
            )
        
        response = tokenizer.decode(output[0][input_ids.shape[1]:], skip_special_tokens=True)
        
        print(f"\nğŸ’¬ {question}")
        print(f"ğŸ¤– {response[:500]}")
        print("-"*60)

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", default="ue_sft_pure", help="æ¨¡å‹åç§°")
    args = parser.parse_args()
    test_model(args.model)
