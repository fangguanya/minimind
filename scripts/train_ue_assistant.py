"""
UnrealEngine ä»£ç åŠ©æ‰‹è®­ç»ƒä¸»è„šæœ¬
================================

è¿™æ˜¯ä¸€ä¸ªä¸€ç«™å¼è®­ç»ƒè„šæœ¬ï¼ŒåŒ…å«ï¼š
1. æ•°æ®å‡†å¤‡
2. é¢„è®­ç»ƒï¼ˆPretrainï¼‰
3. ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰
4. è¯„ä¼°æµ‹è¯•

ä½¿ç”¨æ–¹æ³•ï¼š
python train_ue_assistant.py --ue_source_path "D:/UnrealEngine/Engine/Source" --stage all
"""

import os
import sys
import argparse
import subprocess
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.append(str(PROJECT_ROOT))


def run_command(cmd: str, description: str = ""):
    """è¿è¡Œå‘½ä»¤"""
    print(f"\n{'='*60}")
    print(f"ğŸš€ {description}")
    print(f"{'='*60}")
    print(f"å‘½ä»¤: {cmd}\n")
    
    result = subprocess.run(cmd, shell=True, cwd=str(PROJECT_ROOT))
    
    if result.returncode != 0:
        print(f"âŒ å‘½ä»¤æ‰§è¡Œå¤±è´¥: {description}")
        return False
    
    print(f"âœ… {description} å®Œæˆ!")
    return True


def prepare_data(args):
    """å‡†å¤‡æ•°æ®"""
    print("\n" + "="*60)
    print("ğŸ“¦ Step 1: å‡†å¤‡è®­ç»ƒæ•°æ®")
    print("="*60)
    
    # 1.1 å‡†å¤‡Pretrainæ•°æ®
    if not os.path.exists(f"{PROJECT_ROOT}/dataset/ue_pretrain.jsonl") or args.force_regenerate:
        cmd = (
            f"python scripts/prepare_ue_pretrain_data.py "
            f"--ue_source_path \"{args.ue_source_path}\" "
            f"--output_path dataset/ue_pretrain.jsonl "
            f"--chunk_size {args.chunk_size} "
            f"--max_file_size {args.max_file_size}"
        )
        if args.max_pretrain_samples:
            cmd += f" --max_samples {args.max_pretrain_samples}"
        
        run_command(cmd, "ç”ŸæˆPretrainæ•°æ®é›†")
    else:
        print("ğŸ“ Pretrainæ•°æ®é›†å·²å­˜åœ¨ï¼Œè·³è¿‡ç”Ÿæˆ")
    
    # 1.2 å‡†å¤‡SFTæ•°æ®
    if not os.path.exists(f"{PROJECT_ROOT}/dataset/ue_sft.jsonl") or args.force_regenerate:
        cmd = (
            f"python scripts/prepare_ue_sft_data.py "
            f"--ue_source_path \"{args.ue_source_path}\" "
            f"--output_path dataset/ue_sft.jsonl"
        )
        if args.max_sft_files:
            cmd += f" --max_files {args.max_sft_files}"
        
        run_command(cmd, "ç”ŸæˆSFTæ•°æ®é›†")
    else:
        print("ğŸ“ SFTæ•°æ®é›†å·²å­˜åœ¨ï¼Œè·³è¿‡ç”Ÿæˆ")
    
    # 1.3 åˆå¹¶é€šç”¨SFTæ•°æ®ï¼ˆå¯é€‰ï¼‰
    if args.include_general_sft and os.path.exists(f"{PROJECT_ROOT}/dataset/sft_mini_512.jsonl"):
        print("ğŸ“ å°†åˆå¹¶é€šç”¨SFTæ•°æ®ä»¥ä¿æŒé€šç”¨å¯¹è¯èƒ½åŠ›")
        merge_datasets(
            [f"{PROJECT_ROOT}/dataset/ue_sft.jsonl", 
             f"{PROJECT_ROOT}/dataset/sft_mini_512.jsonl"],
            f"{PROJECT_ROOT}/dataset/ue_sft_merged.jsonl"
        )


def merge_datasets(input_files: list, output_file: str):
    """åˆå¹¶å¤šä¸ªæ•°æ®é›†"""
    import json
    
    all_data = []
    for f in input_files:
        if os.path.exists(f):
            with open(f, 'r', encoding='utf-8') as fp:
                for line in fp:
                    if line.strip():
                        all_data.append(json.loads(line))
    
    import random
    random.shuffle(all_data)
    
    with open(output_file, 'w', encoding='utf-8') as fp:
        for item in all_data:
            fp.write(json.dumps(item, ensure_ascii=False) + '\n')
    
    print(f"âœ… åˆå¹¶å®Œæˆ: {len(all_data)} æ¡æ•°æ® -> {output_file}")


def run_pretrain(args):
    """è¿è¡Œé¢„è®­ç»ƒ"""
    print("\n" + "="*60)
    print("ğŸ“ Step 2: é¢„è®­ç»ƒ (Pretrain)")
    print("="*60)
    
    # æ£€æŸ¥æ•°æ®
    pretrain_data = f"{PROJECT_ROOT}/dataset/ue_pretrain_chunked.jsonl"
    if not os.path.exists(pretrain_data):
        pretrain_data = f"{PROJECT_ROOT}/dataset/ue_pretrain.jsonl"
    
    if not os.path.exists(pretrain_data):
        print("âŒ é¢„è®­ç»ƒæ•°æ®ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®å‡†å¤‡é˜¶æ®µ")
        return False
    
    cmd = (
        f"python trainer/train_pretrain.py "
        f"--data_path {pretrain_data} "
        f"--hidden_size {args.hidden_size} "
        f"--num_hidden_layers {args.num_hidden_layers} "
        f"--epochs {args.pretrain_epochs} "
        f"--batch_size {args.batch_size} "
        f"--learning_rate {args.pretrain_lr} "
        f"--max_seq_len {args.max_seq_len} "
        f"--save_weight ue_pretrain "
        f"--log_interval 50 "
        f"--save_interval 500"
    )
    
    if args.use_wandb:
        cmd += " --use_wandb --wandb_project MiniMind-UE-Pretrain"
    
    return run_command(cmd, "UEä»£ç é¢„è®­ç»ƒ")


def run_sft(args):
    """è¿è¡ŒSFTå¾®è°ƒ"""
    print("\n" + "="*60)
    print("ğŸ’¬ Step 3: ç›‘ç£å¾®è°ƒ (SFT)")
    print("="*60)
    
    # é€‰æ‹©SFTæ•°æ®
    if args.include_general_sft and os.path.exists(f"{PROJECT_ROOT}/dataset/ue_sft_merged.jsonl"):
        sft_data = f"{PROJECT_ROOT}/dataset/ue_sft_merged.jsonl"
    else:
        sft_data = f"{PROJECT_ROOT}/dataset/ue_sft.jsonl"
    
    if not os.path.exists(sft_data):
        print("âŒ SFTæ•°æ®ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®å‡†å¤‡é˜¶æ®µ")
        return False
    
    cmd = (
        f"python trainer/train_full_sft.py "
        f"--data_path {sft_data} "
        f"--hidden_size {args.hidden_size} "
        f"--num_hidden_layers {args.num_hidden_layers} "
        f"--epochs {args.sft_epochs} "
        f"--batch_size {args.batch_size} "
        f"--learning_rate {args.sft_lr} "
        f"--max_seq_len {args.max_seq_len} "
        f"--from_weight ue_pretrain "
        f"--save_weight ue_sft "
        f"--log_interval 50 "
        f"--save_interval 500"
    )
    
    if args.use_wandb:
        cmd += " --use_wandb --wandb_project MiniMind-UE-SFT"
    
    return run_command(cmd, "UEåŠ©æ‰‹SFTå¾®è°ƒ")


def run_eval(args):
    """è¯„ä¼°æ¨¡å‹"""
    print("\n" + "="*60)
    print("ğŸ§ª Step 4: æ¨¡å‹è¯„ä¼°")
    print("="*60)
    
    # æµ‹è¯•é—®é¢˜
    test_questions = [
        "ä»€ä¹ˆæ˜¯AActorç±»ï¼Ÿ",
        "UActorComponentå’ŒAActoræœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
        "å¦‚ä½•åœ¨UEä¸­å®ç°TickåŠŸèƒ½ï¼Ÿ",
        "UPROPERTYå®æœ‰å“ªäº›å¸¸ç”¨å‚æ•°ï¼Ÿ",
        "UEä¸­å¦‚ä½•åˆ›å»ºå®šæ—¶å™¨ï¼Ÿ",
        "ä»€ä¹ˆæ˜¯UEçš„åå°„ç³»ç»Ÿï¼Ÿ",
        "ACharacterç±»åœ¨å“ªä¸ªæ–‡ä»¶ä¸­å®šä¹‰ï¼Ÿ",
    ]
    
    print("\nğŸ“ æµ‹è¯•é—®é¢˜åˆ—è¡¨:")
    for i, q in enumerate(test_questions, 1):
        print(f"  {i}. {q}")
    
    print("\nå¯åŠ¨äº¤äº’å¼æµ‹è¯•...")
    
    cmd = (
        f"python eval_llm.py "
        f"--load_from model "
        f"--weight ue_sft "
        f"--hidden_size {args.hidden_size} "
        f"--num_hidden_layers {args.num_hidden_layers}"
    )
    
    return run_command(cmd, "æ¨¡å‹è¯„ä¼°")


def print_training_plan(args):
    """æ‰“å°è®­ç»ƒè®¡åˆ’"""
    print("\n" + "="*60)
    print("ğŸ“‹ UEä»£ç åŠ©æ‰‹è®­ç»ƒè®¡åˆ’")
    print("="*60)
    
    print(f"""
ğŸ”§ è®­ç»ƒé…ç½®:
    - UEæºä»£ç è·¯å¾„: {args.ue_source_path}
    - æ¨¡å‹éšè—å±‚ç»´åº¦: {args.hidden_size}
    - æ¨¡å‹å±‚æ•°: {args.num_hidden_layers}
    - æœ€å¤§åºåˆ—é•¿åº¦: {args.max_seq_len}
    - Batch Size: {args.batch_size}
    
ğŸ“Š è®­ç»ƒé˜¶æ®µ:
    Stage 1: æ•°æ®å‡†å¤‡
        - æå–UEæºä»£ç  -> ue_pretrain.jsonl
        - ç”ŸæˆQAå¯¹ -> ue_sft.jsonl
        
    Stage 2: é¢„è®­ç»ƒ ({args.pretrain_epochs} epochs, lr={args.pretrain_lr})
        - å­¦ä¹ UEä»£ç é£æ ¼å’ŒçŸ¥è¯†
        - è¾“å‡º: out/ue_pretrain_{args.hidden_size}.pth
        
    Stage 3: SFTå¾®è°ƒ ({args.sft_epochs} epochs, lr={args.sft_lr})
        - å­¦ä¹ é—®ç­”å¯¹è¯æ ¼å¼
        - è¾“å‡º: out/ue_sft_{args.hidden_size}.pth
        
    Stage 4: è¯„ä¼°æµ‹è¯•
        - äº¤äº’å¼é—®ç­”æµ‹è¯•
        
ğŸ’¡ é¢„è®¡èµ„æºæ¶ˆè€—:
    - æ˜¾å­˜: ~4-8GB (æ ¹æ®æ¨¡å‹å¤§å°)
    - é¢„è®­ç»ƒæ—¶é—´: å–å†³äºæ•°æ®é‡
    - SFTæ—¶é—´: é€šå¸¸è¾ƒå¿«
""")


def main():
    parser = argparse.ArgumentParser(description="UEä»£ç åŠ©æ‰‹ä¸€ç«™å¼è®­ç»ƒè„šæœ¬")
    
    # æ•°æ®ç›¸å…³
    parser.add_argument('--ue_source_path', type=str, required=True,
                        help="UEæºä»£ç ç›®å½•è·¯å¾„ (ä¾‹å¦‚: D:/UnrealEngine/Engine/Source)")
    parser.add_argument('--force_regenerate', action='store_true',
                        help="å¼ºåˆ¶é‡æ–°ç”Ÿæˆæ•°æ®é›†")
    parser.add_argument('--max_pretrain_samples', type=int, default=None,
                        help="æœ€å¤§é¢„è®­ç»ƒæ ·æœ¬æ•°")
    parser.add_argument('--max_sft_files', type=int, default=None,
                        help="æœ€å¤§SFTå¤„ç†æ–‡ä»¶æ•°")
    parser.add_argument('--chunk_size', type=int, default=512,
                        help="ä»£ç å—å¤§å°")
    parser.add_argument('--max_file_size', type=int, default=100,
                        help="æœ€å¤§æ–‡ä»¶å¤§å°(KB)")
    parser.add_argument('--include_general_sft', action='store_true',
                        help="åŒ…å«é€šç”¨SFTæ•°æ®ä»¥ä¿æŒå¯¹è¯èƒ½åŠ›")
    
    # æ¨¡å‹ç›¸å…³
    parser.add_argument('--hidden_size', type=int, default=768,
                        help="éšè—å±‚ç»´åº¦ (512=Small, 768=Base)")
    parser.add_argument('--num_hidden_layers', type=int, default=16,
                        help="éšè—å±‚æ•°é‡ (8=Small, 16=Base)")
    parser.add_argument('--max_seq_len', type=int, default=512,
                        help="æœ€å¤§åºåˆ—é•¿åº¦")
    
    # è®­ç»ƒç›¸å…³
    parser.add_argument('--pretrain_epochs', type=int, default=2,
                        help="é¢„è®­ç»ƒè½®æ•°")
    parser.add_argument('--sft_epochs', type=int, default=3,
                        help="SFTè½®æ•°")
    parser.add_argument('--pretrain_lr', type=float, default=5e-4,
                        help="é¢„è®­ç»ƒå­¦ä¹ ç‡")
    parser.add_argument('--sft_lr', type=float, default=1e-5,
                        help="SFTå­¦ä¹ ç‡")
    parser.add_argument('--batch_size', type=int, default=16,
                        help="Batchå¤§å°")
    parser.add_argument('--use_wandb', action='store_true',
                        help="ä½¿ç”¨WandBè®°å½•è®­ç»ƒ")
    
    # æ‰§è¡Œé˜¶æ®µ
    parser.add_argument('--stage', type=str, default='all',
                        choices=['all', 'data', 'pretrain', 'sft', 'eval', 'plan'],
                        help="æ‰§è¡Œé˜¶æ®µ")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è·¯å¾„
    if not os.path.exists(args.ue_source_path) and args.stage not in ['plan', 'eval']:
        print(f"âŒ UEæºä»£ç è·¯å¾„ä¸å­˜åœ¨: {args.ue_source_path}")
        print("\nè¯·ç¡®ä¿è·¯å¾„æ­£ç¡®ï¼Œä¾‹å¦‚:")
        print("  - Windows: D:/UnrealEngine/Engine/Source")
        print("  - Linux: /home/user/UnrealEngine/Engine/Source")
        return
    
    # æ‰“å°è®­ç»ƒè®¡åˆ’
    print_training_plan(args)
    
    if args.stage == 'plan':
        return
    
    # æ‰§è¡Œå„é˜¶æ®µ
    stages_to_run = {
        'all': ['data', 'pretrain', 'sft', 'eval'],
        'data': ['data'],
        'pretrain': ['pretrain'],
        'sft': ['sft'],
        'eval': ['eval'],
    }
    
    stages = stages_to_run[args.stage]
    
    if 'data' in stages:
        prepare_data(args)
    
    if 'pretrain' in stages:
        if not run_pretrain(args):
            print("é¢„è®­ç»ƒå¤±è´¥ï¼Œåœæ­¢åç»­é˜¶æ®µ")
            return
    
    if 'sft' in stages:
        if not run_sft(args):
            print("SFTå¤±è´¥ï¼Œåœæ­¢åç»­é˜¶æ®µ")
            return
    
    if 'eval' in stages:
        run_eval(args)
    
    print("\n" + "="*60)
    print("ğŸ‰ æ‰€æœ‰é˜¶æ®µå®Œæˆ!")
    print("="*60)
    print(f"""
ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:
    - dataset/ue_pretrain.jsonl (é¢„è®­ç»ƒæ•°æ®)
    - dataset/ue_sft.jsonl (SFTæ•°æ®)
    - out/ue_pretrain_{args.hidden_size}.pth (é¢„è®­ç»ƒæ¨¡å‹)
    - out/ue_sft_{args.hidden_size}.pth (æœ€ç»ˆæ¨¡å‹)

ğŸš€ ä½¿ç”¨æ¨¡å‹:
    python eval_llm.py --weight ue_sft --hidden_size {args.hidden_size}
    
ğŸ’¡ è¿›ä¸€æ­¥ä¼˜åŒ–å»ºè®®:
    1. å¢åŠ æ›´å¤šé«˜è´¨é‡æ‰‹åŠ¨QAå¯¹
    2. ä½¿ç”¨LoRAå¾®è°ƒç‰¹å®šé¢†åŸŸ
    3. è€ƒè™‘ç»“åˆRAGæå‡æ£€ç´¢å‡†ç¡®æ€§
""")


if __name__ == '__main__':
    main()
